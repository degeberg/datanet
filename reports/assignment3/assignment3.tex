% This is "sig-alternate.tex" V1.9 April 2009
% This file should be compiled with V2.4 of "sig-alternate.cls" April 2009
%
% This has been modified for use in the Principles of Computer System Design @
% DIKU, 2010/2011
\documentclass{sig-alternate}
%
% This gets rid of the copyright box which is not needed for PCSD assignments
%
\makeatletter
\def\@copyrightspace{}
\makeatother
%
% For our purposes page numbers are not so bad
%
\pagenumbering{arabic}

%
% Useful packages
%
\usepackage{url}
\usepackage[english]{babel}
%\usepackage[british]{babel}
\usepackage{hyperref}
%\usepackage{graphicx} % uncomment if you are using graphics

\usepackage{listings}
\lstset{
    keywordstyle=\bfseries\ttfamily\color[rgb]{0,0,1},
    identifierstyle=\ttfamily,
    commentstyle=\color[rgb]{0.133,0.545,0.133},
    stringstyle=\ttfamily\color[rgb]{0.627,0.126,0.941},
    showstringspaces=false,
    basicstyle=\footnotesize,
    numbersep=10pt,
    tabsize=2,
    breaklines=true,
    prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
    breakatwhitespace=false,
    aboveskip={1.5\baselineskip},
    columns=fixed,
    upquote=true,
    extendedchars=true,
    frame=single,
    captionpos=b
}

\usepackage[margin=11pt,font=footnotesize,labelfont=bf]{caption}

\begin{document}

\title{Datanet: Assignment 3}
\subtitle{Anonymizing Distributed Proxy}

\numberofauthors{1} % This is individual work right???

\author{
\alignauthor
    Daniel Egeberg\\
    \email{egeberg@diku.dk}
}

\maketitle

\begin{abstract}
    This report outlines the design and implementation of an anonymizing
    distributed proxy network. Code from an existing proxy server was modified
    to interact with a network of peers to hide the requester's IP address
    from the destination host.

    Security measures and error handling is discussed, and three different
    experiments have been conducted to test latency and bandwidth of the
    network. Additionally, the overall design of the protocol is discussed
    shortly.
\end{abstract}

\section{Implementation}
\label{sec:implementation}

The distributed proxy network is handled by introducing a new object called
a \verb+ProxyManager+ found in the \verb+proxynet+ module. This object is
responsible for storing data about the network as it is received by the
network's tracker. The main server thread runs this object in a new thread.
When the proxy manager thread starts, it registers with the tracker and
receives the latest peer list and whitelist. It registers with the tracker and
gets updated lists again after \verb+min_wait+ seconds have passed.

An additional configuration flag has been added that contains the domain name
of the tracker. The proxy network is \emph{only} used if this setting is
non-empty on startup.

The server's caching capabilities have been disabled by changing the
\verb+cache+ module so it always reports resources as non-cachable and
not cached. This was done to make sure that any problems with the caching
mechanism would not manifest in the testing of the distributed network.


\section{Security Measures}
\label{sec:security}

In order to restrict which requests the client can make, a whitelist has been
implemented. The whitelist consists of a list of fully qualified domain names
given by the peer tracker. Only request URIs that have a domain name in the
whitelist, or whose domain name is a subdomain of a whitelisted domain is
allowed. All other requests will result in a 403 response code.


\section{Error Handling}
\label{sec:errorhandling}

Seeing as peers are only removed from the tracker list daily, you will often
get a lot of peers that are no longer running or for some other reason are
unresponsive. To deal with this problem, all proxy requests have a fixed
timeout. If the request times out, the peer in question is regarded as a
bad peer and removed from the local peer list. That peer will be taken into
consideration again if it is still in the tracker once the server updates with
the tracker. If the request times out, another peer will not be tried and a
504 Gateway Timeout response is given to the client.

One problem with this approach is that a peer may be removed even though
the problem resides with another peer further ahead in the request chain.
As an example, if our request gets routed through proxies A, B and C and
proxy C happens to be a bad peer, we will be removing proxy A from the list
because it from our point of view seems unresponsive, even though it only
timed out because proxy B timed out, which in turn timed out because of proxy
C. There is no easy way around this problem seeing as we have no knowledge
nor control of what happens when we forward a request to another peer. The
only way to make sure we only remove \emph{actual} bad peers is by using the
\verb+Max-Forwards+ header to make sure that the next peer will be the final
one. However, this goes against the purpose of the network.


\section{Protocol Problems}
\label{sec:problems}

There are a number of problems with the protocol. It requires a lot of
functional and active peers at any one time in order to work reliably. In its
current state, it consists mostly of a few unreliable or entirely unresponsive
peers. If the request is routed through five different peers, it only takes
one of them timing out. Currently, the tracker consists of a lot of peers of
varying quality because people are still actively developing them. Also, a lot
of the peers are actually offline because they were only registered to test.

For real-world purposes, it would be necessary having a production \emph{and}
testing/development tracker. Also, the expiry should probably be lowered to
decrease the chance of listing peers that are no longer active. The tracker
could also periodically check that the registered peers are still online
instead of relying on a fixed expiry time.

An easy way to disrupt the network would be to register a lot of invalid
peers. This would in practice give a high probability of getting a valid peer
selecting one of these. Depending on the strategy of the peer, this would
either make the network much slower or make requests fail. Lowering the expiry
time or making the tracker check for live registered peers.


\section{Setup}
\label{sec:setup}

My proxy peer is running as a daemon on my VPS in Linode's London datacenter.
The server is running Gentoo Linux and Python 3.2 compiled directly from the
source tarball from upstream seeing as the latest version in Portage is 3.1,
and the server uses things that were added to the standard library in 3.2.

The server's firewall does not restrict port usage, but the proxy server only
binds to a specific port on all network interfaces.


\section{Experiments}
\label{sec:experiments}

To test the proxy network, I have conducted three different kinds of tests:

\begin{enumerate}
    \item Using it through a browser.
    \item Benchmarking using Apache Bench.
    \item Downloading a large file.
\end{enumerate}

\subsection{Browser usage}
\label{sec:browser}

Testing the proxy network through a browser was done by using the ``Network''
tab in Chromium's developer tool, to get the total download time for the
webpage and all the resources. The results in \autoref{tbl:browser} shows
download times for requests made to \url{http://diku.dk/}.

\begin{table}[h]
\centering
\begin{tabular}{|l||r|}
\hline
\bf{With proxy?} & \bf{Average download time:} \\
\hline\hline
No & 0.34s \\ \hline
Yes & 44.89s \\
\hline
\end{tabular}
\caption{Browser test results.}
\label{tbl:browser}
\end{table}


\subsection{Apache Bench}
\label{sec:ab}

Apache Bench was used to test making concurrent requests through the network.
I made 100 requests to \url{http://diku.dk/} with a concurrency level of 10.
The total time was 62496~ms with a median time of 900~ms and a maximum time of
40928~ms. The response time was pretty unstable with a standard deviation of
8963~ms.

I was unable to get Apache Bench working with my own peer, so the
initial request through the network was made to the super peer at
\texttt{46.137.49.145}.

Using the same settings, but without using the proxy network, the total
response time was 472~ms, the median was 43~ms, the maximum was 113~ms and the
standard deviation was 17~ms.


\subsection{Download of large files}
\label{sec:debian}

To test bandwidth, a Debian
image\footnote{\url{http://ftp.dk.debian.org/debian-cd/current/i386/iso-cd/debian-6.0.1a-i386-businesscard.iso}}
was downloaded four times both directly and through the proxy.
\autoref{tbl:debian} shows the results of this experiment.

\begin{table}[h]
\centering
\begin{tabular}{|l||r|}
\hline
\bf{With proxy?} & \bf{Average download speed:} \\
\hline\hline
No & 6.27 MB/s \\ \hline
Yes & 848 kB/s \\
\hline
\end{tabular}
\caption{Download times for the Debian image.}
\label{tbl:debian}
\end{table}


\subsection{Conclusion}
\label{sec:expconclusion}

The tests in subsections \ref{sec:browser} and \ref{sec:ab} show that making
requests through the proxy network causes a significant increase in latency.
The Apache Bench experiment (\autoref{sec:ab}) also shows that the network is
unstable and response times may vary greatly. The test in \autoref{sec:debian}
also shows that the bandwidth is lower when using the network.

Overall, there are significant performance penalties when using the proxy
network.


\section{Known problems}

This assignment's code was based on the code from the previous assignments,
so it has the same limitations as outlined in previous reports. The proxy
functionality in my implementation seems somewhat unstable, but I'm not
entirely sure if it is the network in general or a local problem. I haven't
had time to implement it using the code from the suggested solutions, but I
will most likely use that as a basis for the next assignment.


%\bibliographystyle{abbrv}
%\bibliography{pcsd}  % pcsd.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
%  or
% pdflatex bibtexx pdflatex pdflatex
% to resolve all references

%APPENDICES are optional
%\balancecolumns
%\appendix
%Appendix A
%\section{Headings in Appendices}

\end{document}
